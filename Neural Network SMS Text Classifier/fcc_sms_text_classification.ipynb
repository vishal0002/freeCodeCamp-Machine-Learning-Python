{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{},"colab":{"name":"fcc_sms_text_classification.ipynb","private_outputs":true,"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# get data files\n!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n\ntrain_file_path = \"train-data.tsv\"\ntest_file_path = \"valid-data.tsv\"","metadata":{"id":"lMHwYXHXCar3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_table('train-data.tsv',header=None)\ndf_val = pd.read_table('valid-data.tsv',header=None)","metadata":{"id":"g_h508FEClxO"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.columns = ['label', 'message']\ndf_val.columns = ['label', 'message']","metadata":{"id":"Eb9zvKgfcw1T"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head()","metadata":{"id":"44NLpATRbEur"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le = LabelEncoder()\ny_train = le.fit_transform(df_train['label'])\ny_val = le.transform(df_val['label'])","metadata":{"id":"o_SZUFKAZEsf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = Tokenizer(oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(df_train['message'])","metadata":{"id":"zOMKywn4zReN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\nmax_length = 100\ntrunc_type = 'post'\npadding_type = 'post'","metadata":{"id":"9VnEB8wadQdr"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nX_train = pad_sequences(tokenizer.texts_to_sequences(df_train['message']),\n                        maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\nX_val = pad_sequences(tokenizer.texts_to_sequences(df_val['message']),\n                      maxlen=max_length, padding=padding_type, truncating=trunc_type)","metadata":{"id":"dOZNN6RadQX7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, 64, input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"id":"DSs92DlqdQRr"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=2)","metadata":{"id":"SGRXe3fkdQIz"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# function to predict messages based on model\n# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\ndef predict_message(pred_text):\n    seq = tokenizer.texts_to_sequences([pred_text])\n    padded = pad_sequences(seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\n    # Predict probability\n    prob = model.predict(padded)[0][0]\n\n    # Label based on threshold\n    label = 'spam' if prob > 0.5 else 'ham'\n    return  (prob,label)\n\npred_text = \"how are you doing today?\"\n\nprediction = predict_message(pred_text)\nprint(prediction)\nprint(predict_message(\"sale today! to stop texts call 98912460324\"))","metadata":{"id":"J9tD9yACG6M9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run this cell to test your function and model. Do not modify contents.\ndef test_predictions():\n  test_messages = [\"how are you doing today\",\n                   \"sale today! to stop texts call 98912460324\",\n                   \"i dont want to go. can we try it a different day? available sat\",\n                   \"our new mobile video service is live. just install on your phone to start watching.\",\n                   \"you have won Â£1000 cash! call to claim your prize.\",\n                   \"i'll bring it tomorrow. don't forget the milk.\",\n                   \"wow, is your arm alright. that happened to me one time too\"\n                  ]\n\n  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n  passed = True\n\n  for msg, ans in zip(test_messages, test_answers):\n    prediction = predict_message(msg)\n\n    if prediction[1] != ans:\n      passed = False\n      #print(passed)\n  if passed:\n    print(\"You passed the challenge. Great job!\")\n  else:\n    print(\"You haven't passed yet. Keep trying.\")\n\ntest_predictions()\n","metadata":{"id":"Dxotov85SjsC"},"outputs":[],"execution_count":null}]}